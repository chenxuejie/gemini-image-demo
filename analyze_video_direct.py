"""
ç›´æ¥ä½¿ç”¨ google-genai SDK åˆ†æè§†é¢‘å¹¶æ˜¾ç¤ºè¯¦ç»†çš„ Token ä¿¡æ¯
ä¸ä½¿ç”¨ LangChainï¼Œæœ€å¿«çš„è°ƒç”¨æ–¹å¼ï¼Œå…³é—­ thinking æ¨¡å¼
"""

import base64
import os
import time
from google import genai
from google.genai import types

# é…ç½®
PROJECT_ID = "cloud-llm-preview1"
LOCATION = "us-central1"
MODEL_ID = "gemini-2.5-flash"
VIDEO_PATH = "1.ts"


def analyze_video_with_token_details(video_path: str, prompt: str):
    """
    ä½¿ç”¨ google-genai SDK åˆ†æè§†é¢‘å¹¶æ‰“å°è¯¦ç»†çš„ Token ä¿¡æ¯å’Œå¤„ç†æ—¶é—´
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        prompt: åˆ†ææç¤ºè¯
    """
    print("=" * 80)
    print("Gemini è§†é¢‘åˆ†æ - Token è¯¦ç»†ä¿¡æ¯ (Direct API)")
    print("=" * 80)
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    print(f"\nè§†é¢‘è·¯å¾„: {video_path}")
    print(f"æ¨¡å‹: {MODEL_ID}")
    print(f"Thinking: å…³é—­")
    print(f"Prompt: {prompt}")
    
    # è¯»å–è§†é¢‘å¹¶è½¬æ¢ä¸º base64
    with open(video_path, 'rb') as f:
        video_bytes = f.read()
    
    file_size_kb = len(video_bytes) / 1024
    file_size_mb = file_size_kb / 1024
    print(f"è§†é¢‘å¤§å°: {file_size_kb:.2f} KB ({file_size_mb:.2f} MB)")
    
    # ç¡®å®š MIME ç±»å‹
    if video_path.lower().endswith('.mp4'):
        mime_type = 'video/mp4'
    elif video_path.lower().endswith('.ts'):
        mime_type = 'video/mp2t'
    elif video_path.lower().endswith('.mov'):
        mime_type = 'video/quicktime'
    elif video_path.lower().endswith('.avi'):
        mime_type = 'video/x-msvideo'
    elif video_path.lower().endswith('.webm'):
        mime_type = 'video/webm'
    elif video_path.lower().endswith('.mkv'):
        mime_type = 'video/x-matroska'
    else:
        mime_type = 'video/mp4'
    
    print(f"MIME ç±»å‹: {mime_type}")
    
    print("\n" + "-" * 80)
    print("å¼€å§‹è°ƒç”¨ Gemini API...")
    print("-" * 80)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        # åˆ›å»º genai å®¢æˆ·ç«¯
        client = genai.Client(
            vertexai=True,
            project=PROJECT_ID,
            location=LOCATION,
        )
        
        # åˆ›å»ºè§†é¢‘å†…å®¹
        video_part = types.Part.from_bytes(
            data=video_bytes,
            mime_type=mime_type
        )
        
        # é…ç½®ç”Ÿæˆå‚æ•° - å…³é—­ thinking æ¨¡å¼ï¼Œè®¾ç½® media resolution ä¸º low
        generate_config = types.GenerateContentConfig(
            thinking_config=types.ThinkingConfig(
                thinking_budget=0  # å…³é—­ thinking
            ),
            media_resolution="MEDIA_RESOLUTION_MEDIUM"  # è®¾ç½® media resolution ä¸º medium
        )
        
        # è°ƒç”¨æ¨¡å‹
        response = client.models.generate_content(
            model=MODEL_ID,
            contents=[video_part, prompt],
            config=generate_config
        )
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        processing_time = end_time - start_time
        
        print("\n" + "=" * 80)
        print("å¤„ç†æ—¶é—´")
        print("=" * 80)
        print(f"æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        
        print("\n" + "=" * 80)
        print("Token ä½¿ç”¨è¯¦æƒ…")
        print("=" * 80)
        
        # æå– usage_metadata
        usage_metadata = response.usage_metadata
        
        if usage_metadata:
            print(f"\nğŸ“Š Input Tokens (æ€»è®¡): {usage_metadata.prompt_token_count}")
            print(f"ğŸ“Š Output Tokens (æ€»è®¡): {usage_metadata.candidates_token_count}")
            print(f"ğŸ“Š Total Tokens: {usage_metadata.total_token_count}")
            
            # æ‰“å° Thinking Tokens
            if hasattr(usage_metadata, 'thoughts_token_count'):
                print(f"ğŸ’­ Thinking Tokens: {usage_metadata.thoughts_token_count}")
            
            # æ‰“å° Cached Content Tokens
            if hasattr(usage_metadata, 'cached_content_token_count'):
                print(f"ğŸ“¦ Cached Content Tokens: {usage_metadata.cached_content_token_count}")
            
            # æ‰“å°è¯¦ç»†çš„ token ä¿¡æ¯
            print("\n" + "-" * 40)
            print("Input Tokens è¯¦æƒ…:")
            print("-" * 40)
            
            if hasattr(usage_metadata, 'prompt_tokens_details') and usage_metadata.prompt_tokens_details:
                modality_names = {1: 'TEXT', 2: 'IMAGE', 3: 'VIDEO', 4: 'AUDIO'}
                for detail in usage_metadata.prompt_tokens_details:
                    modality = detail.modality if hasattr(detail, 'modality') else 0
                    token_count = detail.token_count if hasattr(detail, 'token_count') else 0
                    if modality == 2:
                        print(f"  ğŸ–¼ï¸  Image Tokens: {token_count}")
                    elif modality == 1:
                        print(f"  ğŸ“ Text Tokens: {token_count}")
                    elif modality == 3:
                        print(f"  ğŸ¬ Video Tokens: {token_count}")
                    elif modality == 4:
                        print(f"  ğŸ”Š Audio Tokens: {token_count}")
                    else:
                        modality_name = modality_names.get(modality, f'UNKNOWN({modality})')
                        print(f"  â“ {modality_name} Tokens: {token_count}")
            
            print("\n" + "-" * 40)
            print("Output Tokens è¯¦æƒ…:")
            print("-" * 40)
            
            if hasattr(usage_metadata, 'candidates_tokens_details') and usage_metadata.candidates_tokens_details:
                for detail in usage_metadata.candidates_tokens_details:
                    modality = detail.modality if hasattr(detail, 'modality') else 0
                    token_count = detail.token_count if hasattr(detail, 'token_count') else 0
                    if modality == 2:
                        print(f"  ğŸ–¼ï¸  Image Tokens: {token_count}")
                    elif modality == 1:
                        print(f"  ğŸ“ Text Tokens: {token_count}")
                    elif modality == 3:
                        print(f"  ğŸ¬ Video Tokens: {token_count}")
                    elif modality == 4:
                        print(f"  ğŸ”Š Audio Tokens: {token_count}")
                    else:
                        modality_name = modality_names.get(modality, f'UNKNOWN({modality})')
                        print(f"  â“ {modality_name} Tokens: {token_count}")
        else:
            print("æœªè·å–åˆ° usage_metadata")
        
        # æ‰“å° AI å“åº”å†…å®¹
        print("\n" + "=" * 80)
        print("AI å“åº”å†…å®¹")
        print("=" * 80)
        print(response.text)
        
        print("\n" + "=" * 80)
        print(f"åˆ†æå®Œæˆ! æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        print("=" * 80)
        
        return response
        
    except Exception as e:
        end_time = time.time()
        processing_time = end_time - start_time
        print(f"\nâŒ é”™è¯¯ (å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’): {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ä¸»å‡½æ•°"""
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    video_path = os.path.join(script_dir, VIDEO_PATH)
    
    # åˆ†æè§†é¢‘
    analyze_video_with_token_details(
        video_path=video_path,
        prompt="è¯·è¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘çš„å†…å®¹ï¼ŒåŒ…æ‹¬åœºæ™¯ã€äººç‰©ã€åŠ¨ä½œå’Œä»»ä½•é‡è¦çš„äº‹ä»¶ã€‚"
    )


if __name__ == "__main__":
    main()
