"""
ä½¿ç”¨ ChatVertexAI åˆ†æè§†é¢‘å¹¶æ˜¾ç¤ºè¯¦ç»†çš„ Token ä¿¡æ¯
åŒ…æ‹¬ video token, text token ç­‰è¯¦ç»†ä¿¡æ¯ï¼Œä»¥åŠå¤„ç†æ—¶é—´
"""

import base64
import os
import time
from typing import Optional
from pydantic import Field
from langchain_google_vertexai import ChatVertexAI
from langchain_core.messages import HumanMessage

# é…ç½®
PROJECT_ID = "cloud-llm-preview1"
LOCATION = "us-central1"
MODEL_ID = "gemini-2.5-flash"
VIDEO_PATH = "1.ts"


class ChatVertexAIWithMediaResolution(ChatVertexAI):
    """
    ç»§æ‰¿ ChatVertexAIï¼Œæ·»åŠ  media_resolution æ”¯æŒã€‚
    """
    
    default_media_resolution: Optional[str] = Field(default=None)
    
    def invoke(self, input, config=None, *, stop=None, **kwargs):
        """é‡å†™ invoke æ–¹æ³•ï¼Œæ³¨å…¥ media_resolution å‚æ•°"""
        if 'media_resolution' not in kwargs and self.default_media_resolution:
            resolution_map = {
                'low': 'MEDIA_RESOLUTION_LOW',
                'medium': 'MEDIA_RESOLUTION_MEDIUM',
                'high': 'MEDIA_RESOLUTION_HIGH',
                'unspecified': 'MEDIA_RESOLUTION_UNSPECIFIED'
            }
            enum_value = resolution_map.get(self.default_media_resolution, self.default_media_resolution)
            kwargs['media_resolution'] = enum_value
            print(f"[ChatVertexAIWithMediaResolution] æ³¨å…¥ media_resolution={enum_value}")
        
        return super().invoke(input, config, stop=stop, **kwargs)


def analyze_video_with_token_details(video_path: str, prompt: str, media_resolution: str = 'medium'):
    """
    ä½¿ç”¨ LangChain ChatVertexAI åˆ†æè§†é¢‘å¹¶æ‰“å°è¯¦ç»†çš„ Token ä¿¡æ¯å’Œå¤„ç†æ—¶é—´
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        prompt: åˆ†ææç¤ºè¯
        media_resolution: åª’ä½“åˆ†è¾¨ç‡ (low, medium, high)
    """
    print("=" * 80)
    print("Gemini è§†é¢‘åˆ†æ - Token è¯¦ç»†ä¿¡æ¯")
    print("=" * 80)
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    print(f"\nè§†é¢‘è·¯å¾„: {video_path}")
    print(f"æ¨¡å‹: {MODEL_ID}")
    print(f"Media Resolution: {media_resolution}")
    print(f"Prompt: {prompt}")
    
    # è¯»å–è§†é¢‘å¹¶è½¬æ¢ä¸º base64
    with open(video_path, 'rb') as f:
        video_bytes = f.read()
    
    video_base64 = base64.b64encode(video_bytes).decode('utf-8')
    file_size_kb = len(video_bytes) / 1024
    file_size_mb = file_size_kb / 1024
    print(f"è§†é¢‘å¤§å°: {file_size_kb:.2f} KB ({file_size_mb:.2f} MB)")
    
    # ç¡®å®š MIME ç±»å‹
    if video_path.lower().endswith('.mp4'):
        mime_type = 'video/mp4'
    elif video_path.lower().endswith('.ts'):
        mime_type = 'video/mp2t'
    elif video_path.lower().endswith('.mov'):
        mime_type = 'video/quicktime'
    elif video_path.lower().endswith('.avi'):
        mime_type = 'video/x-msvideo'
    elif video_path.lower().endswith('.webm'):
        mime_type = 'video/webm'
    elif video_path.lower().endswith('.mkv'):
        mime_type = 'video/x-matroska'
    else:
        mime_type = 'video/mp4'
    
    print(f"MIME ç±»å‹: {mime_type}")
    
    print("\n" + "-" * 80)
    print("å¼€å§‹è°ƒç”¨ Gemini API...")
    print("-" * 80)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        # åˆ›å»º ChatVertexAIWithMediaResolution å®ä¾‹
        llm = ChatVertexAIWithMediaResolution(
            model=MODEL_ID,
            project=PROJECT_ID,
            location=LOCATION,
            default_media_resolution=media_resolution
        )
        
        # åˆ›å»ºåŒ…å«è§†é¢‘çš„æ¶ˆæ¯
        message = HumanMessage(
            content=[
                {
                    "type": "media",
                    "mime_type": mime_type,
                    "data": video_base64
                },
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        )
        
        # è°ƒç”¨æ¨¡å‹
        response = llm.invoke([message])
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        processing_time = end_time - start_time
        
        print("\n" + "=" * 80)
        print("å¤„ç†æ—¶é—´")
        print("=" * 80)
        print(f"æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        
        print("\n" + "=" * 80)
        print("Token ä½¿ç”¨è¯¦æƒ…")
        print("=" * 80)
        
        # æå– usage_metadata
        usage_metadata = getattr(response, 'usage_metadata', None)
        
        if usage_metadata:
            print(f"\nğŸ“Š Input Tokens (æ€»è®¡): {usage_metadata.get('input_tokens', 'N/A')}")
            print(f"ğŸ“Š Output Tokens (æ€»è®¡): {usage_metadata.get('output_tokens', 'N/A')}")
            print(f"ğŸ“Š Total Tokens: {usage_metadata.get('total_tokens', 'N/A')}")
            
            # æ‰“å°è¯¦ç»†çš„ token ä¿¡æ¯
            print("\n" + "-" * 40)
            print("å®Œæ•´ usage_metadata å†…å®¹:")
            print("-" * 40)
            for key, value in usage_metadata.items():
                print(f"  {key}: {value}")
        else:
            print("æœªè·å–åˆ° usage_metadata")
        
        # ä» response_metadata ä¸­æå–æ›´è¯¦ç»†çš„ token ä¿¡æ¯
        response_metadata = getattr(response, 'response_metadata', None)
        if response_metadata and 'usage_metadata' in response_metadata:
            detailed_usage = response_metadata['usage_metadata']
            
            print("\n" + "=" * 80)
            print("è¯¦ç»† Token åˆ†è§£ (æ¥è‡ª response_metadata)")
            print("=" * 80)
            
            # Prompt tokens è¯¦æƒ…
            prompt_tokens_details = detailed_usage.get('prompt_tokens_details', [])
            if prompt_tokens_details:
                print("\nğŸ“¥ Input Tokens è¯¦æƒ…:")
                print("-" * 40)
                modality_names = {1: 'TEXT', 2: 'IMAGE', 3: 'VIDEO', 4: 'AUDIO'}
                for detail in prompt_tokens_details:
                    modality = detail.get('modality', 0)
                    token_count = detail.get('token_count', 0)
                    modality_name = modality_names.get(modality, f'UNKNOWN({modality})')
                    if modality == 2:  # IMAGE
                        print(f"  ğŸ–¼ï¸  Image Tokens: {token_count}")
                    elif modality == 1:  # TEXT
                        print(f"  ğŸ“ Text Tokens: {token_count}")
                    elif modality == 3:  # VIDEO
                        print(f"  ğŸ¬ Video Tokens: {token_count}")
                    elif modality == 4:  # AUDIO
                        print(f"  ğŸ”Š Audio Tokens: {token_count}")
                    else:
                        print(f"  â“ {modality_name} Tokens: {token_count}")
            
            # Candidates tokens è¯¦æƒ…
            candidates_tokens_details = detailed_usage.get('candidates_tokens_details', [])
            if candidates_tokens_details:
                print("\nğŸ“¤ Output Tokens è¯¦æƒ…:")
                print("-" * 40)
                for detail in candidates_tokens_details:
                    modality = detail.get('modality', 0)
                    token_count = detail.get('token_count', 0)
                    modality_name = modality_names.get(modality, f'UNKNOWN({modality})')
                    if modality == 2:  # IMAGE
                        print(f"  ğŸ–¼ï¸  Image Tokens: {token_count}")
                    elif modality == 1:  # TEXT
                        print(f"  ğŸ“ Text Tokens: {token_count}")
                    elif modality == 3:  # VIDEO
                        print(f"  ğŸ¬ Video Tokens: {token_count}")
                    elif modality == 4:  # AUDIO
                        print(f"  ğŸ”Š Audio Tokens: {token_count}")
                    else:
                        print(f"  â“ {modality_name} Tokens: {token_count}")
            
            # å…¶ä»– token ä¿¡æ¯
            print("\nğŸ“‹ å…¶ä»– Token ä¿¡æ¯:")
            print("-" * 40)
            print(f"  ğŸ’­ Thinking Tokens: {detailed_usage.get('thoughts_token_count', 0)}")
            print(f"  ğŸ“¦ Cached Content Tokens: {detailed_usage.get('cached_content_token_count', 0)}")
            
            # Cache tokens è¯¦æƒ…
            cache_tokens_details = detailed_usage.get('cache_tokens_details', [])
            if cache_tokens_details:
                print(f"  Cache Tokens Details: {cache_tokens_details}")
            
            # åŸå§‹ token è®¡æ•°
            print("\nğŸ“Š åŸå§‹ Token è®¡æ•°:")
            print("-" * 40)
            print(f"  prompt_token_count: {detailed_usage.get('prompt_token_count', 0)}")
            print(f"  candidates_token_count: {detailed_usage.get('candidates_token_count', 0)}")
            print(f"  total_token_count: {detailed_usage.get('total_token_count', 0)}")
        
        # æ‰“å° AI å“åº”å†…å®¹
        print("\n" + "=" * 80)
        print("AI å“åº”å†…å®¹")
        print("=" * 80)
        print(response.content if hasattr(response, 'content') else str(response))
        
        print("\n" + "=" * 80)
        print(f"åˆ†æå®Œæˆ! æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        print("=" * 80)
        
        return response
        
    except Exception as e:
        end_time = time.time()
        processing_time = end_time - start_time
        print(f"\nâŒ é”™è¯¯ (å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’): {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ä¸»å‡½æ•°"""
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    video_path = os.path.join(script_dir, VIDEO_PATH)
    
    # åˆ†æè§†é¢‘
    analyze_video_with_token_details(
        video_path=video_path,
        prompt="è¯·è¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘çš„å†…å®¹ï¼ŒåŒ…æ‹¬åœºæ™¯ã€äººç‰©ã€åŠ¨ä½œå’Œä»»ä½•é‡è¦çš„äº‹ä»¶ã€‚",
        media_resolution='medium'
    )


if __name__ == "__main__":
    main()
